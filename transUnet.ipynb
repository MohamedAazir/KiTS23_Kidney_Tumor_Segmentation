{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3e1c5115",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e1c5115",
        "outputId": "302c6e13-cd08-4d19-dc7b-8f6b7dd2fab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (5.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchsummary einops transformers nibabel tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "class CTDataset(Dataset):\n",
        "    def __init__(self, image_dir, label_dir, transform=None):\n",
        "        self.images = sorted(glob.glob(f\"{image_dir}/*.nii.gz\"))\n",
        "        self.labels = sorted(glob.glob(f\"{label_dir}/*.nii.gz\"))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = nib.load(self.images[idx]).get_fdata().astype(np.float32)\n",
        "        lbl = nib.load(self.labels[idx]).get_fdata().astype(np.int64)\n",
        "\n",
        "        img = np.expand_dims(img, axis=0)  # Add channel dimension\n",
        "        if self.transform:\n",
        "            img, lbl = self.transform(img, lbl)\n",
        "        return torch.tensor(img), torch.tensor(lbl)\n"
      ],
      "metadata": {
        "id": "IYUOOdcayV7a"
      },
      "id": "IYUOOdcayV7a",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class KiTS23Dataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        root_dir: \"/content/kits23/dataset/\"\n",
        "        Each case folder should have 'imaging.nii.gz' and 'segmentation.nii.gz'\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.case_folders = sorted(\n",
        "            [os.path.join(root_dir, d) for d in os.listdir(root_dir)\n",
        "             if os.path.isdir(os.path.join(root_dir, d))]\n",
        "        )\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.case_folders)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        case_path = self.case_folders[idx]\n",
        "        img_path = os.path.join(case_path, \"imaging.nii.gz\")\n",
        "        lbl_path = os.path.join(case_path, \"segmentation.nii.gz\")\n",
        "\n",
        "        # Load NIfTI\n",
        "        img = nib.load(img_path).get_fdata().astype(np.float32)\n",
        "        lbl = nib.load(lbl_path).get_fdata().astype(np.int64)\n",
        "\n",
        "        # Add channel dimension for PyTorch (C, H, W, D)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        if self.transform:\n",
        "            img, lbl = self.transform(img, lbl)\n",
        "\n",
        "        return torch.tensor(img), torch.tensor(lbl)\n",
        "\n",
        "# Example usage\n",
        "dataset = KiTS23Dataset(\"/content/kits23/dataset/\")\n",
        "train_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Check one batch\n",
        "for imgs, lbls in train_loader:\n",
        "    print(\"Image shape:\", imgs.shape)\n",
        "    print(\"Label shape:\", lbls.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "ov_WbVjRzoGq",
        "outputId": "73e0be5a-cf98-45d0-f588-76c5d902f82b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ov_WbVjRzoGq",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 1, 553, 512, 512])\n",
            "Label shape: torch.Size([1, 553, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class KiTS23SliceDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Convert each 3D case to 2D slices along axial plane\n",
        "        \"\"\"\n",
        "        self.slice_data = []  # list of tuples: (image_slice, label_slice)\n",
        "        self.transform = transform\n",
        "\n",
        "        case_folders = sorted([\n",
        "            os.path.join(root_dir, d) for d in os.listdir(root_dir)\n",
        "            if os.path.isdir(os.path.join(root_dir, d))\n",
        "        ])\n",
        "\n",
        "        for case in case_folders:\n",
        "            img_nii = os.path.join(case, \"imaging.nii.gz\")\n",
        "            lbl_nii = os.path.join(case, \"segmentation.nii.gz\")\n",
        "\n",
        "            img = nib.load(img_nii).get_fdata().astype(np.float32)\n",
        "            lbl = nib.load(lbl_nii).get_fdata().astype(np.int64)\n",
        "\n",
        "            # normalize CT values [-1000, 400] -> [-1, 1]\n",
        "            img = np.clip(img, -1000, 400)\n",
        "            img = (img + 1000) / 1400  # 0-1\n",
        "            img = img * 2 - 1  # -1 to 1\n",
        "\n",
        "            # slice along z-axis\n",
        "            for i in range(img.shape[2]):\n",
        "                img_slice = img[:, :, i]\n",
        "                lbl_slice = lbl[:, :, i]\n",
        "\n",
        "                # skip empty slices\n",
        "                if np.sum(lbl_slice) == 0:\n",
        "                    continue\n",
        "\n",
        "                self.slice_data.append((img_slice, lbl_slice))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slice_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, lbl = self.slice_data[idx]\n",
        "        img = np.expand_dims(img, 0)  # add channel dimension\n",
        "        if self.transform:\n",
        "            img, lbl = self.transform(img, lbl)\n",
        "        return torch.tensor(img, dtype=torch.float32), torch.tensor(lbl, dtype=torch.long)\n",
        "\n",
        "# Example usage\n",
        "dataset = KiTS23SliceDataset(\"/content/kits23/dataset/\")\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "print(\"Total slices:\", len(dataset))\n",
        "imgs, lbls = next(iter(train_loader))\n",
        "print(\"Batch shapes:\", imgs.shape, lbls.shape)\n"
      ],
      "metadata": {
        "id": "826yFHwc2jyG"
      },
      "id": "826yFHwc2jyG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXcd_7nM3TXR"
      },
      "id": "WXcd_7nM3TXR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}