{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13422956,"sourceType":"datasetVersion","datasetId":8519473},{"sourceId":13424151,"sourceType":"datasetVersion","datasetId":8520299},{"sourceId":13427590,"sourceType":"datasetVersion","datasetId":8522575},{"sourceId":13429940,"sourceType":"datasetVersion","datasetId":8523913},{"sourceId":612256,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":459936,"modelId":475773},{"sourceId":613629,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":461058,"modelId":476826}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"3c7811f7-fd47-4489-ba06-13b8b2da46a8","cell_type":"markdown","source":"# Setting Up the Environment","metadata":{}},{"id":"9a36a132-b222-4a2d-9098-1bec7d66e700","cell_type":"code","source":"# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# install nnunetv2\n!pip install nnunetv2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"cad31d10-65aa-48c0-8c4f-f904df027c18","cell_type":"code","source":"# check nnunetv2\nimport nnunetv2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fcbc7504-4fbf-4896-8722-393911c596fe","cell_type":"code","source":"# Make Directory to store Models\n!mkdir -p /kaggle/working/nnUNet_models/Dataset500_KiTS2023","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"25f657dd-8d04-42c4-8b2b-469ae237c6d0","cell_type":"code","source":"# Make Directory to align with nnUNet\n!mkdir -p /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f07f9f0d-14b8-4979-8d71-82d49d4e4f0a","cell_type":"code","source":"# Make Directory to align with nnUNet\n!mkdir -p /kaggle/working/nnUNet_preprocessed","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"66edf744-0f76-43b7-9dc6-2cf609963633","cell_type":"code","source":"import os\n\n# Raw data (can be empty if you only do inference)\nos.environ[\"nnUNet_raw\"] = \"/kaggle/working/nnUNet_raw\"\n\n# Preprocessed data (can be empty if you only do inference)\nos.environ[\"nnUNet_preprocessed\"] = \"/kaggle/working/nnUNet_preprocessed\"\n\n# Model results folder (where your Dataset700_MYTASK lives)\nos.environ[\"nnUNet_results\"] = \"/kaggle/working/nnUNet_models\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T02:27:46.436118Z","iopub.execute_input":"2025-10-20T02:27:46.436867Z","iopub.status.idle":"2025-10-20T02:27:46.441383Z","shell.execute_reply.started":"2025-10-20T02:27:46.436837Z","shell.execute_reply":"2025-10-20T02:27:46.440529Z"}},"outputs":[],"execution_count":5},{"id":"aacd515c-1ea7-429d-9fff-697016bee07f","cell_type":"code","source":"# #Code to remove file\n# import os\n\n# file_path = \"/kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imaging_001_0000.nii.gz\"\n\n# if os.path.exists(file_path):\n#     os.remove(file_path)\n#     print(\"File deleted:\", file_path)\n# else:\n#     print(\"File not found:\", file_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bf0d1902-f747-4d51-93a5-c729eb8bafca","cell_type":"code","source":"# # Code to remove folder\n# import shutil\n\n# folder_path = \"/kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTr\"\n\n# # Remove the folder and everything inside\n# shutil.rmtree(folder_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"39df3b61-59cc-4ec5-bc9e-021170f397ac","cell_type":"markdown","source":"# Data Loading & Pre-Processing","metadata":{}},{"id":"a059196c-9577-4525-b2c0-2c3f19c68fe7","cell_type":"code","source":"import os\nimport SimpleITK as sitk\n\n# === Directories ===\ninput_base = '/kaggle/input/nnunet-training/first50/imagesTr'\noutput_base = '/kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTr'\nos.makedirs(output_base, exist_ok=True)\n\n# === Range of cases to convert ===\nfor i in range(0, 40):  \n    case_id = f\"imaging_{i:03d}_0000.nii\"\n    input_folder = os.path.join(input_base, case_id)\n    input_file = os.path.join(input_folder, \"imaging.nii\")\n    output_file = os.path.join(output_base, f\"{case_id}.gz\")  # final output: imaging_000_0000.nii.gz\n    \n    print(f\"\\n Processing: {input_file}\")\n    \n    try:\n        # Read input .nii\n        img = sitk.ReadImage(input_file)\n        \n        # Write compressed .nii.gz\n        writer = sitk.ImageFileWriter()\n        writer.SetFileName(output_file)\n        writer.UseCompressionOn()\n        writer.Execute(img)\n        \n        # Show success message\n        print(f\" Saved compressed file: {output_file}\")\n        \n        # Optional: check size\n        original_size = os.path.getsize(input_file) / (1024 * 1024)\n        compressed_size = os.path.getsize(output_file) / (1024 * 1024)\n        print(f\"   Original: {original_size:.2f} MB | Compressed: {compressed_size:.2f} MB\")\n        \n    except Exception as e:\n        print(f\" Error processing {input_file}: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"997dc48a-0817-4493-bca2-df967220fa34","cell_type":"code","source":"import os\nimport SimpleITK as sitk\n\n# === Directories ===\ninput_base = '/kaggle/input/nnunet-training/first50/labelsTr'\noutput_base = '/kaggle/working/nnUNet_raw/Dataset500_KiTS2023/labelsTr'\nos.makedirs(output_base, exist_ok=True)\n\n# === Range of cases to convert ===\nfor i in range(0, 40):  \n    case_id = f\"imaging_{i:03d}.nii\"\n    input_folder = os.path.join(input_base, f\"imaging_{i:03d}.nii\")\n    input_file = os.path.join(input_folder, \"segmentation.nii\")\n    output_file = os.path.join(output_base, f\"{case_id}.gz\")  # final output: imaging_000_0000.nii.gz\n    \n    print(f\"\\n Processing: {input_file}\")\n    \n    try:\n        # Read input .nii\n        img = sitk.ReadImage(input_file)\n        \n        # Write compressed .nii.gz\n        writer = sitk.ImageFileWriter()\n        writer.SetFileName(output_file)\n        writer.UseCompressionOn()\n        writer.Execute(img)\n        \n        # Show success message\n        print(f\" Saved compressed file: {output_file}\")\n        \n        # Optional: check size\n        original_size = os.path.getsize(input_file) / (1024 * 1024)\n        compressed_size = os.path.getsize(output_file) / (1024 * 1024)\n        print(f\"   Original: {original_size:.2f} MB | Compressed: {compressed_size:.2f} MB\")\n        \n    except Exception as e:\n        print(f\" Error processing {input_file}: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0464f6c5-2395-4bcd-a0ca-2e99b2fbf0f8","cell_type":"code","source":"!cp /kaggle/input/nnunet-training/first50/dataset.json /kaggle/working/nnUNet_raw/Dataset500_KiTS2023","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b2c8edc0-89c9-4fe0-bf4e-4eb33653fbfb","cell_type":"code","source":"# Pre processing with reduced workload\nimport os\n\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\nos.environ[\"nnUNet_tmp\"] = \"/content/tmp\"\nos.makedirs(\"/content/tmp\", exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f7b88ed3-1a6b-48ad-9b50-1e9ca4bef447","cell_type":"code","source":"# Data Pre Processing with reduce Workload\n!nnUNetv2_plan_and_preprocess -d 500 -c 3d_fullres --verify_dataset_integrity --verbose -np 2 -pl nnUNetPlannerResEncM","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c50e958e-6073-4ef7-bc52-1b8096554814","cell_type":"markdown","source":"# Model Training","metadata":{}},{"id":"579f051a-95e9-40c3-99aa-2802c9fb6271","cell_type":"code","source":"!nnUNetv2_train Dataset500_KiTS2023 3d_fullres all -p nnUNetResEncUNetMPlans -tr nnUNetTrainer_10epochs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d65fb2b6-9deb-433c-a26d-e3238c59ffda","cell_type":"code","source":"# import nibabel as nib\n# import numpy as np\n# import matplotlib.pyplot as plt\n# from matplotlib.widgets import Slider\n# from matplotlib.colors import ListedColormap\n# from matplotlib.patches import Patch\n\n\n# # Paths\n# ct_path = \"/kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imaging_001_0000.nii.gz\"\n# seg_path = \"/kaggle/working/results/imaging_001.nii.gz\"\n\n# # Load images\n# ct_img = nib.load(ct_path)\n# ct_data = ct_img.get_fdata()\n\n# seg_img = nib.load(seg_path)\n# seg_data = seg_img.get_fdata().astype(int)\n\n# # --- 1. Custom Colors and Masking (Same as before) ---\n# colors = ['#000000', '#9467BD', '#00BCD4', '#8BC34A']\n# cmap = ListedColormap(colors)\n# masked_seg_data = np.ma.masked_where(seg_data == 0, seg_data)\n# cmap.set_bad(color='none', alpha=0.0)\n\n# # --- 2. Function to Get Correct Axial Slice ---\n# def get_axial_slice(data_3d, index, axis=0):\n#     if axis == 0:\n#         slice_2d = data_3d[index, :, :]\n#     elif axis == 1:\n#         slice_2d = data_3d[:, index, :]\n#     else:\n#         slice_2d = data_3d[:, :, index]\n    \n#     # FIX ROTATION: Use np.rot90 instead of .T to correct orientation\n#     # k=1 rotates 90 degrees CCW, k=3 rotates 270 degrees CCW (90 degrees CW)\n#     # This value is often found through trial and error (try k=1, 2, or 3)\n#     return np.rot90(slice_2d, k=1) \n\n# def get_masked_axial_slice(data_3d, index, axis=0):\n#     if axis == 0:\n#         masked_slice = masked_seg_data[index, :, :]\n#     elif axis == 1:\n#         masked_slice = masked_seg_data[:, index, :]\n#     else:\n#         masked_slice = masked_seg_data[:, :, index]\n        \n#     # FIX ROTATION: Apply the same rotation\n#     return np.rot90(masked_slice, k=1) \n\n# # --- 3. Initial Axial Slice Setup ---\n# AXIAL_AXIS = 0 \n# MAX_SLICES = ct_data.shape[AXIAL_AXIS]\n# # FIX COLORS: Set initial slice to a value where structures are present (e.g., 150)\n# slice_idx = 260\n\n# # Plot setup\n# fig, ax = plt.subplots(figsize=(6,6))\n# plt.subplots_adjust(bottom=0.25)\n\n# # Plot the corrected axial slice data\n# img_plot = ax.imshow(get_axial_slice(ct_data, slice_idx, axis=AXIAL_AXIS), cmap='gray', vmin=-100, vmax=300)\n# overlay = ax.imshow(get_masked_axial_slice(seg_data, slice_idx, axis=AXIAL_AXIS), cmap=cmap, alpha=0.5, interpolation='none')\n\n# ax.set_title(f'Axial Slice {slice_idx} of {MAX_SLICES-1}')\n# ax.axis('off')\n\n# # --- 4. Slider and Update Function (Remains the same) ---\n# ax_slider = plt.axes([0.25, 0.1, 0.5, 0.03])\n# slider = Slider(ax_slider, 'Axial Slice', 0, MAX_SLICES-1, valinit=slice_idx, valstep=1)\n\n# def update(val):\n#     idx = int(slider.val)\n#     img_plot.set_data(get_axial_slice(ct_data, idx, axis=AXIAL_AXIS))\n#     overlay.set_data(get_masked_axial_slice(seg_data, idx, axis=AXIAL_AXIS))\n#     ax.set_title(f'Axial Slice {idx} of {MAX_SLICES-1}')\n#     fig.canvas.draw_idle()\n\n# slider.on_changed(update)\n\n# # --- 5. Legend (Same as before) ---\n# legend_elements = [\n#     Patch(facecolor='#9467BD', alpha=0.5, label='Kidney (1)'),\n#     Patch(facecolor='#00BCD4', alpha=0.5, label='Tumor (2)'),\n#     Patch(facecolor='#8BC34A', alpha=0.5, label='Cyst (3)')\n# ]\n# ax.legend(handles=legend_elements, loc='lower right', bbox_to_anchor=(1.0, 0.0), framealpha=0.6)\n\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1745940d-ef9a-49b8-9c68-2945c746e848","cell_type":"markdown","source":"# Prediction & Scores","metadata":{}},{"id":"4c2a8fc5-ad9a-444d-996e-a2baa2abbf53","cell_type":"code","source":"# Loading the Test Images\nimport os\nimport SimpleITK as sitk\n\n# === Directories ===\ninput_base = '/kaggle/input/nnunet-training/first50/imagesTs'\noutput_base = '/kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs'\nos.makedirs(output_base, exist_ok=True)\n\n# === Range of cases to convert ===\nfor i in range(40, 50):  \n    case_id = f\"imaging_{i:03d}_0000.nii\"\n    input_folder = os.path.join(input_base, case_id)\n    input_file = os.path.join(input_folder, \"imaging.nii\")\n    output_file = os.path.join(output_base, f\"{case_id}.gz\")  # final output: imaging_000_0000.nii.gz\n    \n    print(f\"\\n Processing: {input_file}\")\n    \n    try:\n        # Read input .nii\n        img = sitk.ReadImage(input_file)\n        \n        # Write compressed .nii.gz\n        writer = sitk.ImageFileWriter()\n        writer.SetFileName(output_file)\n        writer.UseCompressionOn()\n        writer.Execute(img)\n        \n        # Show success message\n        print(f\" Saved compressed file: {output_file}\")\n        \n        # Optional: check size\n        original_size = os.path.getsize(input_file) / (1024 * 1024)\n        compressed_size = os.path.getsize(output_file) / (1024 * 1024)\n        print(f\"   Original: {original_size:.2f} MB | Compressed: {compressed_size:.2f} MB\")\n        \n    except Exception as e:\n        print(f\" Error processing {input_file}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T02:21:58.427035Z","iopub.execute_input":"2025-10-20T02:21:58.427647Z","iopub.status.idle":"2025-10-20T02:23:39.356954Z","shell.execute_reply.started":"2025-10-20T02:21:58.427623Z","shell.execute_reply":"2025-10-20T02:23:39.355958Z"}},"outputs":[{"name":"stdout","text":"\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_040_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_040_0000.nii.gz\n   Original: 414.00 MB | Compressed: 61.04 MB\n\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_041_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_041_0000.nii.gz\n   Original: 104.00 MB | Compressed: 19.07 MB\n\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_042_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_042_0000.nii.gz\n   Original: 602.00 MB | Compressed: 98.67 MB\n\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_043_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_043_0000.nii.gz\n   Original: 344.00 MB | Compressed: 52.88 MB\n\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_044_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_044_0000.nii.gz\n   Original: 202.00 MB | Compressed: 28.11 MB\n\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_045_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_045_0000.nii.gz\n   Original: 124.00 MB | Compressed: 19.12 MB\n\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_046_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_046_0000.nii.gz\n   Original: 318.00 MB | Compressed: 43.18 MB\n\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_047_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_047_0000.nii.gz\n   Original: 284.00 MB | Compressed: 46.84 MB\n\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_048_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_048_0000.nii.gz\n   Original: 170.00 MB | Compressed: 23.29 MB\n\n Processing: /kaggle/input/nnunet-training/first50/imagesTs/imaging_049_0000.nii/imaging.nii\n Saved compressed file: /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs/imaging_049_0000.nii.gz\n   Original: 1340.00 MB | Compressed: 208.94 MB\n","output_type":"stream"}],"execution_count":1},{"id":"03c0b6bc-bf2e-493e-9c12-e29cb51f9e12","cell_type":"code","source":"!cp -r /kaggle/input/nnunet2nd/pytorch/default/1/pretrained_models/nnUNetTrainer__nnUNetPlans__3d_fullres_batch_4_all /kaggle/working/nnUNet_models/Dataset500_KiTS2023","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"143e3e1e-6f65-41db-9f36-089c9af03f86","cell_type":"code","source":"!cp -r /kaggle/input/nnunet2nd/pytorch/default/1/pretrained_models/nnUNetTrainer__nnUNetPlans__3d_lowres_plain_all /kaggle/working/nnUNet_models/Dataset500_KiTS2023","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dac4912f-0f9c-4465-9f4b-3f3b879e1d3a","cell_type":"code","source":"!cp -r /kaggle/input/nnunet2nd/pytorch/default/1/pretrained_models/nnUNetTrainer__nnUNetPlans__3d_lowres_residual_all /kaggle/working/nnUNet_models/Dataset500_KiTS2023","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4c8df5d5-9639-4ed8-9705-a4d950a63631","cell_type":"code","source":"!cp -r /kaggle/input/custom-nnunet/pytorch/default/1/custom_models/Dataset500_KiTS2023/nnUNetTrainer_10epochs__nnUNetResEncUNetMPlans__3d_fullres /kaggle/working/nnUNet_models/Dataset500_KiTS2023","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T02:24:50.220756Z","iopub.execute_input":"2025-10-20T02:24:50.221200Z","iopub.status.idle":"2025-10-20T02:24:53.928007Z","shell.execute_reply.started":"2025-10-20T02:24:50.221174Z","shell.execute_reply":"2025-10-20T02:24:53.927192Z"}},"outputs":[],"execution_count":2},{"id":"b88c28ef-7bbb-4ac1-96da-3e4780013689","cell_type":"code","source":"# Dir. to store inferencing results\n!mkdir -p /kaggle/working/inference_outs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T02:24:56.364390Z","iopub.execute_input":"2025-10-20T02:24:56.365003Z","iopub.status.idle":"2025-10-20T02:24:56.517999Z","shell.execute_reply.started":"2025-10-20T02:24:56.364974Z","shell.execute_reply":"2025-10-20T02:24:56.516937Z"}},"outputs":[],"execution_count":3},{"id":"c1598e50-1f9f-4d1c-a078-dc7bf5650567","cell_type":"code","source":"# Run the Prediction \n!nnUNetv2_predict -i /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs -o /kaggle/working/inference_outs/Lowres_outs -d 500 -c 3d_lowres_plain_all -f all -chk checkpoint_best.pth","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ed07af73-3212-4e5e-be42-1669f5f91329","cell_type":"code","source":"# Run the Prediction \n!nnUNetv2_predict -i /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs -o /kaggle/working/inference_outs/Lowres_residual_outs -d 500 -c 3d_lowres_residual_all -f all","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"aa93ef7a-1857-4d91-a0a6-4db792c95aed","cell_type":"code","source":"# Run the Prediction \n!nnUNetv2_predict -i /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs -o /kaggle/working/inference_outs/Fullres_outs -d 500 -c 3d_fullres_batch_4_all -f all","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bff06e53-f3a1-45d1-af8b-98b51b08557a","cell_type":"code","source":"!nnUNetv2_predict \\\n-i /kaggle/working/nnUNet_raw/Dataset500_KiTS2023/imagesTs \\\n-o /kaggle/working/inference_outs/Custom_outs \\\n-d 500 \\\n-c 3d_fullres \\\n-tr nnUNetTrainer_10epochs \\\n-p nnUNetResEncUNetMPlans \\\n-f all \\\n-chk checkpoint_best.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T02:27:53.792502Z","iopub.execute_input":"2025-10-20T02:27:53.793418Z"}},"outputs":[{"name":"stdout","text":"\n#######################################################################\nPlease cite the following paper when using nnU-Net:\nIsensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n#######################################################################\n\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nThere are 10 cases in the source folder\nI am processing 0 out of 1 (max process ID is 0, we start counting with 0!)\nThere are 10 cases that I would like to predict\n","output_type":"stream"}],"execution_count":null},{"id":"fb6d1d95-3264-4d41-b0a4-617a4e2b4828","cell_type":"code","source":"# kits23_compute_metrics FOLDER_WITH_PREDICTIONS\n-num_processes XX","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"81f3419b-2537-4d9a-8e47-5311b1959548","cell_type":"code","source":"!zip -r inference_outs.zip /kaggle/working/inference_outs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"032ab459-ec77-4872-9f1a-322ff3671430","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}