{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"88c00661","cell_type":"code","source":"!pip install nibabel monai timm torchmetrics\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9e187b3d-268d-4314-843c-d424d160bc2c","cell_type":"code","source":"#clear directory\n!cd /kaggle/working/\n!rm -rf *","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"547cd121-5308-483c-af18-8b087358fc46","cell_type":"code","source":"!pip install gdown\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e5701dd7-c6bd-4255-b2a3-c8e85b0d8e7d","cell_type":"code","source":"import gdown\n\n#https://drive.google.com/file/d/1tUArfL0QHhd0XkfXX1FnExF8_PbABtDQ/view?usp=sharing\n\nfile_id = \"1tUArfL0QHhd0XkfXX1FnExF8_PbABtDQ\"  # replace with your file ID\nurl = f\"https://drive.google.com/uc?id={file_id}\"\n\noutput_path = \"/kaggle/working/kits23.zip\"\ngdown.download(url, output_path, quiet=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T08:57:46.974631Z","iopub.execute_input":"2025-10-19T08:57:46.975408Z","iopub.status.idle":"2025-10-19T08:58:04.825148Z","shell.execute_reply.started":"2025-10-19T08:57:46.975382Z","shell.execute_reply":"2025-10-19T08:58:04.824494Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1tUArfL0QHhd0XkfXX1FnExF8_PbABtDQ\nFrom (redirected): https://drive.google.com/uc?id=1tUArfL0QHhd0XkfXX1FnExF8_PbABtDQ&confirm=t&uuid=c8edca36-e1b5-49ce-9a89-5ef3a2a715c8\nTo: /kaggle/working/kits23.zip\n100%|██████████| 1.28G/1.28G [00:15<00:00, 82.4MB/s]\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/kits23.zip'"},"metadata":{}}],"execution_count":15},{"id":"d446ba54-4ba6-4d22-9168-2c45a963b1eb","cell_type":"code","source":"import zipfile\n\nzip_path = \"/kaggle/working/kits23.zip\"\nextract_path = \"/kaggle/working/kits23\"\n\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f6b612ac-99e7-4ca7-94c8-b76940b06c8a","cell_type":"code","source":"import os, torch, nibabel as nib\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\n\nclass KiTS23_2p5D(Dataset):\n    def __init__(self, root_dir, cases, num_slices=3, transform=None):\n        self.root_dir = root_dir\n        self.cases = cases\n        self.num_slices = num_slices\n        self.transform = transform\n        self.samples = []\n        self._prepare_samples()\n\n    def _prepare_samples(self):\n        for case in self.cases:\n            img_path = os.path.join(self.root_dir, case, \"imaging.nii.gz\")\n            lbl_path = os.path.join(self.root_dir, case, \"segmentation.nii.gz\")\n            img = nib.load(img_path).get_fdata()\n            lbl = nib.load(lbl_path).get_fdata()\n            img = (img - np.mean(img)) / (np.std(img) + 1e-5)\n\n            for z in range(1, img.shape[2]-1):\n                self.samples.append((img[..., z-1:z+2], lbl[..., z]))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        stack, mask = self.samples[idx]\n        stack = torch.tensor(stack).float().permute(2, 0, 1)  # (3,H,W)\n        mask = torch.tensor(mask).long()  # (H,W)\n        return stack, mask\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"85fe48f5-55c6-4330-a293-d3e38cd8103d","cell_type":"code","source":"root = \"/kaggle/working/kits23/kits23\"\ncases = sorted(os.listdir(root))[:10]  # use only 50 cases\n\ntrain_cases = cases[:7]\nval_cases = cases[7:]\n\ntrain_ds = KiTS23_2p5D(root, train_cases)\nval_ds   = KiTS23_2p5D(root, val_cases)\n\ntrain_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"12f87405-2455-4185-85ca-4fa15480e77e","cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())  # should be True\nprint(torch.cuda.device_count())  # should match Kaggle GPU (1 or 2)\nprint(torch.cuda.get_device_name(0))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"71a61d46-2940-417a-929e-71542e028807","cell_type":"code","source":"import torch.nn as nn\nfrom monai.networks.blocks import UnetOutBlock\nfrom timm.models.vision_transformer import vit_base_patch16_224\n\nclass TransUNet2p5D(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3):\n        super().__init__()\n        self.vit = vit_base_patch16_224(pretrained=True)\n        self.vit.conv_proj = nn.Conv2d(in_channels, 768, kernel_size=16, stride=16)\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(768, 256, 2, 2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(256, 128, 2, 2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, 2, 2),\n            nn.ReLU(),\n            nn.Conv2d(64, out_channels, 1)\n        )\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        y = self.vit.conv_proj(x)\n        y = y.flatten(2).transpose(1, 2)\n        y = self.vit.blocks(y)\n        y = y.transpose(1, 2).reshape(B, 768, H//16, W//16)\n        y = self.decoder(y)\n        return y\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dda92a57-68f5-4b4a-b9b9-265965be08b4","cell_type":"code","source":"import torch.nn.functional as F\n\ndef dice_loss(pred, target, eps=1e-5):\n    pred = torch.softmax(pred, dim=1)\n    target_1hot = F.one_hot(target, num_classes=3).permute(0,3,1,2)\n    inter = (pred * target_1hot).sum(dim=(2,3))\n    denom = (pred + target_1hot).sum(dim=(2,3))\n    dice = (2 * inter / (denom + eps)).mean()\n    return 1 - dice\n\nmodel = TransUNet2p5D(in_channels=3, out_channels=3).cuda()\nopt = torch.optim.AdamW(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0d4fce73-5a26-4067-99ae-ce6814b93706","cell_type":"code","source":"for epoch in range(10):  # 10–20 epochs enough for baseline\n    model.train()\n    total_loss = 0\n    for x, y in train_loader:\n        x, y = x.cuda(), y.cuda()\n        out = model(x)\n        loss = dice_loss(out, y)\n        opt.zero_grad(); loss.backward(); opt.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch}: Train DiceLoss {total_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bade1a60-8dcd-457d-aea9-e2a8d0154443","cell_type":"markdown","source":"new","metadata":{}},{"id":"7a6821d4-236e-477a-888d-a914a9965e8d","cell_type":"code","source":"import os\nimport nibabel as nib\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nclass KiTS23_2p5D_Resized(Dataset):\n    def __init__(self, root_dir, cases, num_slices=3, target_size=(256, 256)):\n        \"\"\"\n        root_dir: folder containing case_00000, case_00001, ...\n        cases: list of case folder names to use\n        num_slices: number of consecutive slices for 2.5D input (usually 3)\n        target_size: (H, W) to resize each slice\n        \"\"\"\n        self.root_dir = root_dir\n        self.cases = cases\n        self.num_slices = num_slices\n        self.target_size = target_size\n        self.samples = []\n        self._prepare_samples()\n\n    def _prepare_samples(self):\n        for case in self.cases:\n            img_path = os.path.join(self.root_dir, case, \"imaging.nii.gz\")\n            lbl_path = os.path.join(self.root_dir, case, \"segmentation.nii.gz\")\n\n            img = nib.load(img_path).get_fdata()\n            lbl = nib.load(lbl_path).get_fdata()\n\n            # Normalize intensity\n            img = (img - np.mean(img)) / (np.std(img) + 1e-5)\n\n            # Generate 2.5D slices\n            for z in range(1, img.shape[2]-1):\n                self.samples.append((img[..., z-1:z+2], lbl[..., z]))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        stack, mask = self.samples[idx]\n\n        # Convert to torch tensors\n        stack = torch.tensor(stack).float().permute(2, 0, 1)  # (C,H,W)\n        mask = torch.tensor(mask).long()                       # (H,W)\n\n        # Resize stack and mask\n        stack = F.interpolate(stack.unsqueeze(0), size=self.target_size, mode='bilinear', align_corners=False).squeeze(0)\n        mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=self.target_size, mode='nearest').squeeze(0).long()\n\n        return stack, mask\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"55a1229a-8bf6-46da-9e2a-4bd018d483fa","cell_type":"code","source":"root = \"/kaggle/working/kits23/kits23\"\ncases = sorted(os.listdir(root))[:10]  # use only 50 cases\ntrain_cases = cases[:7]\nval_cases = cases[7:]\n\ntrain_ds = KiTS23_2p5D_Resized(root, train_cases)\nval_ds   = KiTS23_2p5D_Resized(root, val_cases)\n\ntrain_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=4, num_workers=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f4421ea0-c903-4d65-a7d6-b8c0ed95e509","cell_type":"code","source":"import torch.nn as nn\nfrom monai.networks.blocks import UnetOutBlock\nfrom timm.models.vision_transformer import vit_base_patch16_224\n\nclass TransUNet2p5D(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3):\n        super().__init__()\n        self.vit = vit_base_patch16_224(pretrained=True)\n        self.vit.conv_proj = nn.Conv2d(in_channels, 768, kernel_size=16, stride=16)\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(768, 256, 2, 2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(256, 128, 2, 2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, 2, 2),\n            nn.ReLU(),\n            nn.Conv2d(64, out_channels, 1)\n        )\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        y = self.vit.conv_proj(x)\n        y = y.flatten(2).transpose(1, 2)\n        y = self.vit.blocks(y)\n        y = y.transpose(1, 2).reshape(B, 768, H//16, W//16)\n        y = self.decoder(y)\n        return y\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8cff79e1-8879-4dad-b8d8-5b393c968514","cell_type":"markdown","source":"**Importing model**","metadata":{}},{"id":"30dbee1f-f9b6-408a-ae66-9b73b7680839","cell_type":"code","source":"!pip install monai \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T08:21:32.870372Z","iopub.execute_input":"2025-10-19T08:21:32.871100Z","iopub.status.idle":"2025-10-19T08:21:36.157814Z","shell.execute_reply.started":"2025-10-19T08:21:32.871074Z","shell.execute_reply":"2025-10-19T08:21:36.156665Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: monai in /usr/local/lib/python3.11/dist-packages (1.5.1)\nRequirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.1->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"id":"d1240190-1d37-4dea-9027-5e9143d8e81f","cell_type":"code","source":"import monai\nprint(monai.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T08:21:13.318825Z","iopub.execute_input":"2025-10-19T08:21:13.319382Z","iopub.status.idle":"2025-10-19T08:21:26.361652Z","shell.execute_reply.started":"2025-10-19T08:21:13.319355Z","shell.execute_reply":"2025-10-19T08:21:26.360751Z"}},"outputs":[{"name":"stderr","text":"<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n2025-10-19 08:21:20.905848: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760862080.929296     117 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760862080.936351     117 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"1.5.1\n","output_type":"stream"}],"execution_count":2},{"id":"33d1039b-8919-4d60-832f-d0fb6ddf3d0c","cell_type":"code","source":"!pip install --upgrade monai\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T08:52:55.213339Z","iopub.execute_input":"2025-10-19T08:52:55.213977Z","iopub.status.idle":"2025-10-19T08:52:58.514819Z","shell.execute_reply.started":"2025-10-19T08:52:55.213950Z","shell.execute_reply":"2025-10-19T08:52:58.514034Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: monai in /usr/local/lib/python3.11/dist-packages (1.5.1)\nRequirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.1->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\n","output_type":"stream"}],"execution_count":12},{"id":"32f253fd-e69e-44f9-91ae-1a06dacc4dd9","cell_type":"code","source":"from monai.networks.nets import UNETR\nimport torch\n\nmodel = UNETR(\n    in_channels=1,            # input channels (CT=1)\n    out_channels=3,           # number of segmentation classes\n    img_size=(64, 512, 512),  # D,H,W patch size\n    feature_size=16,          # base feature size\n    hidden_size=768,          # transformer hidden size\n    mlp_dim=3072,             # MLP dimension\n    num_heads=12,             # number of attention heads\n    norm_name='instance',     # normalization type\n    res_block=True            # use residual blocks in encoder\n).cuda()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T08:56:52.590198Z","iopub.execute_input":"2025-10-19T08:56:52.590550Z","iopub.status.idle":"2025-10-19T08:56:53.787449Z","shell.execute_reply.started":"2025-10-19T08:56:52.590525Z","shell.execute_reply":"2025-10-19T08:56:53.786866Z"}},"outputs":[],"execution_count":14},{"id":"5ba91d1f-e895-4c08-a658-9087bebcc94e","cell_type":"code","source":"import nibabel as nib\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass KiTS23Dataset(Dataset):\n    def __init__(self, root_dir, cases, patch_size=(64,512,512)):\n        self.root_dir = root_dir\n        self.cases = cases\n        self.patch_size = patch_size\n\n    def __len__(self):\n        return len(self.cases)\n\n    def __getitem__(self, idx):\n        case = self.cases[idx]\n        img = nib.load(f\"{self.root_dir}/{case}/imaging.nii.gz\").get_fdata()\n        lbl = nib.load(f\"{self.root_dir}/{case}/segmentation.nii.gz\").get_fdata()\n        img = (img - np.mean(img)) / (np.std(img)+1e-5)  # normalize\n\n        # simple center crop to patch_size\n        d, h, w = self.patch_size\n        z = max(0, img.shape[2]//2 - d//2)\n        y = max(0, img.shape[0]//2 - h//2)\n        x = max(0, img.shape[1]//2 - w//2)\n        img_patch = img[y:y+h, x:x+w, z:z+d]\n        lbl_patch = lbl[y:y+h, x:x+w, z:z+d]\n\n        img_patch = torch.tensor(img_patch, dtype=torch.float32).unsqueeze(0)  # (1,D,H,W)\n        lbl_patch = torch.tensor(lbl_patch, dtype=torch.long)                   # (D,H,W)\n        return img_patch, lbl_patch\n\n# Example usage\nroot = \"/kaggle/working/kits23\"\ncases = sorted(os.listdir(root))[:50]\ntrain_cases = cases[:40]\nval_cases = cases[40:]\n\ntrain_ds = KiTS23Dataset(root, train_cases)\nval_ds = KiTS23Dataset(root, val_cases)\n\ntrain_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=1, num_workers=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}