{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"88c00661","cell_type":"code","source":"!pip install nibabel monai timm torchmetrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:01:53.281383Z","iopub.execute_input":"2025-10-19T07:01:53.281574Z","iopub.status.idle":"2025-10-19T07:03:08.774223Z","shell.execute_reply.started":"2025-10-19T07:01:53.281557Z","shell.execute_reply":"2025-10-19T07:03:08.773204Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\nCollecting monai\n  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\nRequirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.8.2)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\nRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (1.26.4)\nRequirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (25.0)\nRequirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.15.0)\nRequirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (1.0.0rc2)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.15.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.19.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.1->monai)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.1->monai)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.1->monai)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.1->monai)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.1->monai)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.1->monai)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.1->monai)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.1->monai)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.1->monai)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.1->monai)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.1->monai) (1.3.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (0.28.1)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (0.19.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.10)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.3.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2025.8.3)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22->nibabel) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22->nibabel) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22->nibabel) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22->nibabel) (2024.2.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->huggingface_hub->timm) (8.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22->nibabel) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm) (1.3.1)\nDownloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed monai-1.5.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"id":"9e187b3d-268d-4314-843c-d424d160bc2c","cell_type":"code","source":"#clear directory\n!cd /kaggle/working/\n!rm -rf *","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:36:22.077233Z","iopub.execute_input":"2025-10-19T07:36:22.077837Z","iopub.status.idle":"2025-10-19T07:36:23.027070Z","shell.execute_reply.started":"2025-10-19T07:36:22.077815Z","shell.execute_reply":"2025-10-19T07:36:23.026195Z"}},"outputs":[],"execution_count":16},{"id":"547cd121-5308-483c-af18-8b087358fc46","cell_type":"code","source":"!pip install gdown\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T06:47:50.962188Z","iopub.execute_input":"2025-10-19T06:47:50.963893Z","iopub.status.idle":"2025-10-19T06:47:55.213424Z","shell.execute_reply.started":"2025-10-19T06:47:50.963814Z","shell.execute_reply":"2025-10-19T06:47:55.212326Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.19.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.15.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.8.3)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":2},{"id":"e5701dd7-c6bd-4255-b2a3-c8e85b0d8e7d","cell_type":"code","source":"import gdown\n\n#https://drive.google.com/file/d/1tUArfL0QHhd0XkfXX1FnExF8_PbABtDQ/view?usp=sharing\n\nfile_id = \"1tUArfL0QHhd0XkfXX1FnExF8_PbABtDQ\"  # replace with your file ID\nurl = f\"https://drive.google.com/uc?id={file_id}\"\n\noutput_path = \"/kaggle/working/kits23.zip\"\ngdown.download(url, output_path, quiet=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:36:35.497307Z","iopub.execute_input":"2025-10-19T07:36:35.497885Z","iopub.status.idle":"2025-10-19T07:36:42.572974Z","shell.execute_reply.started":"2025-10-19T07:36:35.497859Z","shell.execute_reply":"2025-10-19T07:36:42.572228Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1tUArfL0QHhd0XkfXX1FnExF8_PbABtDQ\nFrom (redirected): https://drive.google.com/uc?id=1tUArfL0QHhd0XkfXX1FnExF8_PbABtDQ&confirm=t&uuid=1508cf60-76c8-4bcb-9189-493ef84158f3\nTo: /kaggle/working/kits23.zip\n100%|██████████| 1.28G/1.28G [00:05<00:00, 240MB/s]\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/kits23.zip'"},"metadata":{}}],"execution_count":17},{"id":"d446ba54-4ba6-4d22-9168-2c45a963b1eb","cell_type":"code","source":"import zipfile\n\nzip_path = \"/kaggle/working/kits23.zip\"\nextract_path = \"/kaggle/working/kits23\"\n\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:36:46.445649Z","iopub.execute_input":"2025-10-19T07:36:46.446339Z","iopub.status.idle":"2025-10-19T07:36:56.124762Z","shell.execute_reply.started":"2025-10-19T07:36:46.446317Z","shell.execute_reply":"2025-10-19T07:36:56.124099Z"}},"outputs":[],"execution_count":18},{"id":"f6b612ac-99e7-4ca7-94c8-b76940b06c8a","cell_type":"code","source":"import os, torch, nibabel as nib\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\n\nclass KiTS23_2p5D(Dataset):\n    def __init__(self, root_dir, cases, num_slices=3, transform=None):\n        self.root_dir = root_dir\n        self.cases = cases\n        self.num_slices = num_slices\n        self.transform = transform\n        self.samples = []\n        self._prepare_samples()\n\n    def _prepare_samples(self):\n        for case in self.cases:\n            img_path = os.path.join(self.root_dir, case, \"imaging.nii.gz\")\n            lbl_path = os.path.join(self.root_dir, case, \"segmentation.nii.gz\")\n            img = nib.load(img_path).get_fdata()\n            lbl = nib.load(lbl_path).get_fdata()\n            img = (img - np.mean(img)) / (np.std(img) + 1e-5)\n\n            for z in range(1, img.shape[2]-1):\n                self.samples.append((img[..., z-1:z+2], lbl[..., z]))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        stack, mask = self.samples[idx]\n        stack = torch.tensor(stack).float().permute(2, 0, 1)  # (3,H,W)\n        mask = torch.tensor(mask).long()  # (H,W)\n        return stack, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:05:57.334298Z","iopub.execute_input":"2025-10-19T07:05:57.335130Z","iopub.status.idle":"2025-10-19T07:06:01.271624Z","shell.execute_reply.started":"2025-10-19T07:05:57.335094Z","shell.execute_reply":"2025-10-19T07:06:01.271015Z"}},"outputs":[],"execution_count":5},{"id":"85fe48f5-55c6-4330-a293-d3e38cd8103d","cell_type":"code","source":"root = \"/kaggle/working/kits23/kits23\"\ncases = sorted(os.listdir(root))[:10]  # use only 50 cases\n\ntrain_cases = cases[:7]\nval_cases = cases[7:]\n\ntrain_ds = KiTS23_2p5D(root, train_cases)\nval_ds   = KiTS23_2p5D(root, val_cases)\n\ntrain_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:06:12.760121Z","iopub.execute_input":"2025-10-19T07:06:12.760543Z","iopub.status.idle":"2025-10-19T07:07:01.534730Z","shell.execute_reply.started":"2025-10-19T07:06:12.760522Z","shell.execute_reply":"2025-10-19T07:07:01.533938Z"}},"outputs":[],"execution_count":6},{"id":"12f87405-2455-4185-85ca-4fa15480e77e","cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())  # should be True\nprint(torch.cuda.device_count())  # should match Kaggle GPU (1 or 2)\nprint(torch.cuda.get_device_name(0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:07:20.632483Z","iopub.execute_input":"2025-10-19T07:07:20.632792Z","iopub.status.idle":"2025-10-19T07:07:20.747125Z","shell.execute_reply.started":"2025-10-19T07:07:20.632770Z","shell.execute_reply":"2025-10-19T07:07:20.746377Z"}},"outputs":[{"name":"stdout","text":"True\n2\nTesla T4\n","output_type":"stream"}],"execution_count":7},{"id":"71a61d46-2940-417a-929e-71542e028807","cell_type":"code","source":"import torch.nn as nn\nfrom monai.networks.blocks import UnetOutBlock\nfrom timm.models.vision_transformer import vit_base_patch16_224\n\nclass TransUNet2p5D(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3):\n        super().__init__()\n        self.vit = vit_base_patch16_224(pretrained=True)\n        self.vit.conv_proj = nn.Conv2d(in_channels, 768, kernel_size=16, stride=16)\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(768, 256, 2, 2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(256, 128, 2, 2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, 2, 2),\n            nn.ReLU(),\n            nn.Conv2d(64, out_channels, 1)\n        )\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        y = self.vit.conv_proj(x)\n        y = y.flatten(2).transpose(1, 2)\n        y = self.vit.blocks(y)\n        y = y.transpose(1, 2).reshape(B, 768, H//16, W//16)\n        y = self.decoder(y)\n        return y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:11:19.469079Z","iopub.execute_input":"2025-10-19T07:11:19.469823Z","iopub.status.idle":"2025-10-19T07:11:19.476262Z","shell.execute_reply.started":"2025-10-19T07:11:19.469797Z","shell.execute_reply":"2025-10-19T07:11:19.475450Z"}},"outputs":[],"execution_count":10},{"id":"dda92a57-68f5-4b4a-b9b9-265965be08b4","cell_type":"code","source":"import torch.nn.functional as F\n\ndef dice_loss(pred, target, eps=1e-5):\n    pred = torch.softmax(pred, dim=1)\n    target_1hot = F.one_hot(target, num_classes=3).permute(0,3,1,2)\n    inter = (pred * target_1hot).sum(dim=(2,3))\n    denom = (pred + target_1hot).sum(dim=(2,3))\n    dice = (2 * inter / (denom + eps)).mean()\n    return 1 - dice\n\nmodel = TransUNet2p5D(in_channels=3, out_channels=3).cuda()\nopt = torch.optim.AdamW(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:12:03.991220Z","iopub.execute_input":"2025-10-19T07:12:03.991955Z","iopub.status.idle":"2025-10-19T07:12:08.311009Z","shell.execute_reply.started":"2025-10-19T07:12:03.991929Z","shell.execute_reply":"2025-10-19T07:12:08.310402Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6e3bbfe3fe7438fb9d8f5e87f579b40"}},"metadata":{}}],"execution_count":11},{"id":"0d4fce73-5a26-4067-99ae-ce6814b93706","cell_type":"code","source":"for epoch in range(10):  # 10–20 epochs enough for baseline\n    model.train()\n    total_loss = 0\n    for x, y in train_loader:\n        x, y = x.cuda(), y.cuda()\n        out = model(x)\n        loss = dice_loss(out, y)\n        opt.zero_grad(); loss.backward(); opt.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch}: Train DiceLoss {total_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:12:42.577434Z","iopub.execute_input":"2025-10-19T07:12:42.578248Z","iopub.status.idle":"2025-10-19T07:12:42.953019Z","shell.execute_reply.started":"2025-10-19T07:12:42.578221Z","shell.execute_reply":"2025-10-19T07:12:42.951516Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/2322918148.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n    return [\n           ^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 271, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n"],"ename":"RuntimeError","evalue":"Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n    return [\n           ^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 271, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n","output_type":"error"}],"execution_count":12},{"id":"bade1a60-8dcd-457d-aea9-e2a8d0154443","cell_type":"markdown","source":"new","metadata":{}},{"id":"7a6821d4-236e-477a-888d-a914a9965e8d","cell_type":"code","source":"import os\nimport nibabel as nib\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nclass KiTS23_2p5D_Resized(Dataset):\n    def __init__(self, root_dir, cases, num_slices=3, target_size=(256, 256)):\n        \"\"\"\n        root_dir: folder containing case_00000, case_00001, ...\n        cases: list of case folder names to use\n        num_slices: number of consecutive slices for 2.5D input (usually 3)\n        target_size: (H, W) to resize each slice\n        \"\"\"\n        self.root_dir = root_dir\n        self.cases = cases\n        self.num_slices = num_slices\n        self.target_size = target_size\n        self.samples = []\n        self._prepare_samples()\n\n    def _prepare_samples(self):\n        for case in self.cases:\n            img_path = os.path.join(self.root_dir, case, \"imaging.nii.gz\")\n            lbl_path = os.path.join(self.root_dir, case, \"segmentation.nii.gz\")\n\n            img = nib.load(img_path).get_fdata()\n            lbl = nib.load(lbl_path).get_fdata()\n\n            # Normalize intensity\n            img = (img - np.mean(img)) / (np.std(img) + 1e-5)\n\n            # Generate 2.5D slices\n            for z in range(1, img.shape[2]-1):\n                self.samples.append((img[..., z-1:z+2], lbl[..., z]))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        stack, mask = self.samples[idx]\n\n        # Convert to torch tensors\n        stack = torch.tensor(stack).float().permute(2, 0, 1)  # (C,H,W)\n        mask = torch.tensor(mask).long()                       # (H,W)\n\n        # Resize stack and mask\n        stack = F.interpolate(stack.unsqueeze(0), size=self.target_size, mode='bilinear', align_corners=False).squeeze(0)\n        mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=self.target_size, mode='nearest').squeeze(0).long()\n\n        return stack, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:34:59.841554Z","iopub.execute_input":"2025-10-19T07:34:59.841857Z","iopub.status.idle":"2025-10-19T07:34:59.850112Z","shell.execute_reply.started":"2025-10-19T07:34:59.841837Z","shell.execute_reply":"2025-10-19T07:34:59.849371Z"}},"outputs":[],"execution_count":14},{"id":"55a1229a-8bf6-46da-9e2a-4bd018d483fa","cell_type":"code","source":"root = \"/kaggle/working/kits23/kits23\"\ncases = sorted(os.listdir(root))[:10]  # use only 50 cases\ntrain_cases = cases[:7]\nval_cases = cases[7:]\n\ntrain_ds = KiTS23_2p5D_Resized(root, train_cases)\nval_ds   = KiTS23_2p5D_Resized(root, val_cases)\n\ntrain_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=4, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T07:37:36.613295Z","iopub.execute_input":"2025-10-19T07:37:36.614026Z","iopub.status.idle":"2025-10-19T07:38:44.199255Z","shell.execute_reply.started":"2025-10-19T07:37:36.613996Z","shell.execute_reply":"2025-10-19T07:38:44.198410Z"}},"outputs":[],"execution_count":19}]}